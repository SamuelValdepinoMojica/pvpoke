{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries and Environment\n",
    "Import Stable Baselines3, the custom PVPokeEnv, and other required libraries. Configure environment variables and connect to the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the server.\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "WebSocket connection closed.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import websockets\n",
    "from pydantic import BaseModel\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import json\n",
    "from ClassPVPOKE import PVPokeEnv\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "# Create an instance of the environment and connect to the server\n",
    "env = PVPokeEnv(\"ws://localhost:8000/ws\", \"notebook\", \"pvpoke\")\n",
    "asyncio.run(env.connect())\n",
    "\n",
    "# Check if the environment follows the Gym API\n",
    "check_env(env)\n",
    "\n",
    "# Close the environment connection\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Configure the Agent PPO\n",
    "Create and configure a Stable Baselines3 agent (like PPO or DQN) with appropriate hyperparameters for the PVPoke environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the server.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "360dcc8a72674fefa0a7469209b1e555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WebSocket connection closed.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from ClassPVPOKE import PVPokeEnv\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "\n",
    "env = PVPokeEnv(\"ws://localhost:8000/ws\", \"notebook\", \"pvpoke\")\n",
    "asyncio.run(env.connect())\n",
    "\n",
    "\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    learning_rate=0.0003,\n",
    "    n_steps=256,  # Ajustado para episodios de 30-80 pasos\n",
    "    batch_size=64,\n",
    "    n_epochs=10,\n",
    "    gamma=0.99,\n",
    "    gae_lambda=0.95,\n",
    "    clip_range=0.2,\n",
    "    ent_coef=0.0,\n",
    "    vf_coef=0.5,\n",
    "    max_grad_norm=0.5,\n",
    "    tensorboard_log=\"./ppo_pvpoke_tensorboard/\"\n",
    ")\n",
    "\n",
    "# Create a callback to save the model every 10000 steps\n",
    "checkpoint_callback = CheckpointCallback(save_freq=5000, save_path='./models/ppo_pvpoke', name_prefix='ppo_pvpoke')\n",
    "\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=100000, callback=checkpoint_callback,progress_bar=True)\n",
    "\n",
    "# Save the final model\n",
    "model.save(\"ppo_pvpoke_deoxys-bastidon\")\n",
    "\n",
    "# Close the environment connection\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">WebSocket connection closed.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "WebSocket connection closed.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenar DQN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the server.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9d30a111c1144f69456b0c27ef600c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WebSocket connection closed.\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import asyncio\n",
    "import websockets\n",
    "from pydantic import BaseModel\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import json\n",
    "from ClassPVPOKE import PVPokeEnv\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create and connect environment\n",
    "env = PVPokeEnv(\"ws://localhost:8000/ws\", \"notebook\", \"pvpoke\")\n",
    "asyncio.run(env.connect())\n",
    "\n",
    "# Create DQN agent with appropriate hyperparameters\n",
    "model = DQN(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    learning_rate=1e-3,  # Aumentar la tasa de aprendizaje\n",
    "    buffer_size=25000,  # Reducir el tamaño del buffer\n",
    "    learning_starts=100,  # Reducir el número de pasos antes de empezar a aprender\n",
    "    batch_size=128,  # Reducir el tamaño del batch\n",
    "    gamma=0.99,\n",
    "    train_freq=4,\n",
    "    gradient_steps=1,\n",
    "    target_update_interval=10000,  # Reducir el intervalo de actualización del objetivo\n",
    "    exploration_fraction=0.1,\n",
    "    exploration_initial_eps=1,\n",
    "    exploration_final_eps=0.07,    \n",
    "    tensorboard_log=\"./dqn_pvpoke_tensorboard/deoxys-bastidon\"\n",
    ")\n",
    "# Create checkpoint callback\n",
    "checkpoint_callback = CheckpointCallback(save_freq=5000, save_path='./models/dqn/deoxys-bastidon', name_prefix='dqn_pvpoke')\n",
    "\n",
    "# Train the agent\n",
    "model.learn(total_timesteps = 50000, callback=checkpoint_callback, progress_bar=True)\n",
    "\n",
    "# Save final model\n",
    "model.save(\"dqn_pvpoke_final_deoxys-bastidon\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the server.\n",
      "8\n",
      "4\n",
      "Sending message: reset\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 8 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m next_state \u001b[38;5;241m=\u001b[39m discretize_state(next_state)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Actualizar la tabla Q\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m best_next_action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[43mQ_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     50\u001b[0m td_target \u001b[38;5;241m=\u001b[39m reward \u001b[38;5;241m+\u001b[39m gamma \u001b[38;5;241m*\u001b[39m Q_table[next_state][best_next_action]\n\u001b[0;32m     51\u001b[0m td_error \u001b[38;5;241m=\u001b[39m td_target \u001b[38;5;241m-\u001b[39m Q_table[state][action]\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 8 were indexed"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import asyncio\n",
    "from ClassPVPOKE import PVPokeEnv\n",
    "\n",
    "# Crear y conectar el entorno\n",
    "env = PVPokeEnv(\"ws://localhost:8000/ws\", \"notebook\", \"pvpoke\")\n",
    "asyncio.run(env.connect())\n",
    "\n",
    "# Parámetros de Q-learning\n",
    "alpha = 0.1  # Tasa de aprendizaje\n",
    "gamma = 0.99  # Factor de descuento\n",
    "epsilon = 1.0  # Tasa de exploración inicial\n",
    "epsilon_min = 0.1  # Tasa de exploración mínima\n",
    "epsilon_decay = 0.995  # Decaimiento de la tasa de exploración\n",
    "num_episodes = 1000  # Número de episodios de entrenamiento\n",
    "\n",
    "# Inicializar la tabla Q\n",
    "state_space_size = env.observation_space.shape[0]\n",
    "action_space_size = env.action_space.n\n",
    "print(state_space_size)\n",
    "print(action_space_size)\n",
    "Q_table = np.zeros((state_space_size, action_space_size))\n",
    "\n",
    "# Función para seleccionar una acción usando una política epsilon-greedy\n",
    "def select_action(state):\n",
    "    if np.random.rand() < epsilon:\n",
    "        return env.action_space.sample()  # Explorar: seleccionar una acción aleatoria\n",
    "    else:\n",
    "        return np.argmax(Q_table[state])  # Explotar: seleccionar la acción con el valor Q más alto\n",
    "\n",
    "# Función para discretizar el estado\n",
    "def discretize_state(state):\n",
    "    return tuple((state * 10).astype(int))  # Ajusta según sea necesario para tu entorno\n",
    "\n",
    "# Bucle de entrenamiento\n",
    "for episode in range(num_episodes):\n",
    "    state, _ = env.reset()\n",
    "    state = discretize_state(state)\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        action = select_action(state)\n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "        next_state = discretize_state(next_state)\n",
    "        \n",
    "        # Actualizar la tabla Q\n",
    "        best_next_action = np.argmax(Q_table[next_state])\n",
    "        td_target = reward + gamma * Q_table[next_state][best_next_action]\n",
    "        td_error = td_target - Q_table[state][action]\n",
    "        Q_table[state][action] += alpha * td_error\n",
    "        \n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "    \n",
    "    # Decaer la tasa de exploración\n",
    "    if epsilon > epsilon_min:\n",
    "        epsilon *= epsilon_decay\n",
    "    \n",
    "    print(f\"Episode {episode + 1}/{num_episodes}, Total Reward: {total_reward}\")\n",
    "\n",
    "# Guardar la tabla Q\n",
    "np.save(\"Q_table.npy\", Q_table)\n",
    "\n",
    "# Cerrar el entorno\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probar el agente en un episodio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the server.\n",
      "Loaded model from dqn_pvpoke_final_deoxys-bastidon\n",
      "\n",
      "Episode 1 started\n",
      "Initial observation: [  0.  98.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.   0. 138.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [  7.  98.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.   0. 132.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 14.  94.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.   8. 126.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 21.  90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  16. 120.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 28.  90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  16. 114.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 35.  86.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  24. 108.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 42.  82.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  32. 102.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [49. 82.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 32. 96.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [56. 78.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 40. 90.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [63. 74.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 48. 84.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [70. 74.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 48. 78.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [77. 41.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2.  1. 72.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: -0.29325643300798576\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [84. 41.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2.  1. 66.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [91. 37.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2.  9. 60.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [98. 33.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 17. 54.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  33.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  17.  48.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  29.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  25.  42.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  33.  36.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  33.  30.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  21.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  41.  24.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  17.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  49.  18.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 1\n",
      "Observation: [65. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 49. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: 0.007246376811594203\n",
      "\n",
      "Action taken: 1\n",
      "Observation: [65. 13.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 57. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: -0.04081632653061224\n",
      "\n",
      "Action taken: 3\n",
      "Observation: [65. 13.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 57. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 3\n",
      "Observation: [65. 13.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 57. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 3\n",
      "Observation: [65. 13.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 57. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 3\n",
      "Observation: [65.  9.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 65. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: -0.11081632653061224\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  9.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 65. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.0627536231884058\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 73. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.11081632653061224\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 73. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 73. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 73. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 81. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.11081632653061224\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 81. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 81. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  2. 89. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -1.080204081632653\n",
      "\n",
      "Episode finished with total reward: -2.025942028985507\n",
      "Actions taken in episode: [array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64)]\n",
      "\n",
      "Episode 2 started\n",
      "Initial observation: [  0.  98.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.   0. 138.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [  7.  98.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.   0. 132.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 14.  94.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.   8. 126.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 21.  90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  16. 120.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 28.  90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  16. 114.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 35.  86.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  24. 108.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 42.  82.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  32. 102.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [49. 82.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 32. 96.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [56. 78.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 40. 90.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [63. 74.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 48. 84.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [70. 74.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 48. 78.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [77. 41.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2.  1. 72.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: -0.29325643300798576\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [84. 41.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2.  1. 66.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [91. 37.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2.  9. 60.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [98. 33.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 17. 54.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  33.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  17.  48.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  29.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  25.  42.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  33.  36.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  33.  30.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  21.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  41.  24.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  17.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  49.  18.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 1\n",
      "Observation: [65. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 49. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: 0.007246376811594203\n",
      "\n",
      "Action taken: 1\n",
      "Observation: [65. 13.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 57. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: -0.04081632653061224\n",
      "\n",
      "Action taken: 3\n",
      "Observation: [65. 13.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 57. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 3\n",
      "Observation: [65. 13.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 57. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 3\n",
      "Observation: [65. 13.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 57. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 3\n",
      "Observation: [65.  9.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 65. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: -0.11081632653061224\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  9.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 65. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.0627536231884058\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 73. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.11081632653061224\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 73. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 73. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 73. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 81. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.11081632653061224\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 81. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 81. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  2. 89. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -1.080204081632653\n",
      "\n",
      "Episode finished with total reward: -2.025942028985507\n",
      "Actions taken in episode: [array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64)]\n",
      "\n",
      "Episode 3 started\n",
      "Initial observation: [  0.  98.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.   0. 138.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [  7.  98.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.   0. 132.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 14.  94.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.   8. 126.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 21.  90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  16. 120.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 28.  90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  16. 114.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 35.  86.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  24. 108.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 42.  82.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  32. 102.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [49. 82.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 32. 96.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [56. 78.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 40. 90.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [63. 74.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 48. 84.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [70. 74.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 48. 78.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [77. 41.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2.  1. 72.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: -0.29325643300798576\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [84. 41.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2.  1. 66.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [91. 37.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2.  9. 60.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [98. 33.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 17. 54.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  33.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  17.  48.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  29.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  25.  42.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  33.  36.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  33.  30.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  21.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  41.  24.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  17.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  49.  18.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 1\n",
      "Observation: [65. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 49. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: 0.007246376811594203\n",
      "\n",
      "Action taken: 1\n",
      "Observation: [65. 13.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 57. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: -0.04081632653061224\n",
      "\n",
      "Action taken: 3\n",
      "Observation: [65. 13.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 57. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 3\n",
      "Observation: [65. 13.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 57. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 3\n",
      "Observation: [65. 13.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 57. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 3\n",
      "Observation: [65.  9.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 65. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: -0.11081632653061224\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  9.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 65. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.0627536231884058\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 73. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.11081632653061224\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 73. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 73. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 73. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 81. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.11081632653061224\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 81. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 81. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  2. 89. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -1.080204081632653\n",
      "\n",
      "Episode finished with total reward: -2.025942028985507\n",
      "Actions taken in episode: [array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64)]\n",
      "\n",
      "Episode 4 started\n",
      "Initial observation: [  0.  98.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.   0. 138.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [  7.  98.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.   0. 132.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 14.  94.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.   8. 126.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 21.  90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  16. 120.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 28.  90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  16. 114.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 35.  86.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  24. 108.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 42.  82.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  32. 102.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [49. 82.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 32. 96.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [56. 78.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 40. 90.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [63. 74.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 48. 84.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [70. 74.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 48. 78.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [77. 41.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2.  1. 72.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: -0.29325643300798576\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [84. 41.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2.  1. 66.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [91. 37.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2.  9. 60.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [98. 33.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 17. 54.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  33.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  17.  48.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  29.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  25.  42.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  33.  36.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  33.  30.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  21.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  41.  24.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  17.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  49.  18.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 1\n",
      "Observation: [65. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 49. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: 0.007246376811594203\n",
      "\n",
      "Action taken: 1\n",
      "Observation: [65. 13.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 57. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: -0.04081632653061224\n",
      "\n",
      "Action taken: 3\n",
      "Observation: [65. 13.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 57. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 3\n",
      "Observation: [65. 13.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 57. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 3\n",
      "Observation: [65. 13.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 57. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 3\n",
      "Observation: [65.  9.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 65. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: -0.11081632653061224\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  9.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 65. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.0627536231884058\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 73. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.11081632653061224\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 73. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 73. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 73. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 81. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.11081632653061224\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 81. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 81. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  2. 89. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -1.080204081632653\n",
      "\n",
      "Episode finished with total reward: -2.025942028985507\n",
      "Actions taken in episode: [array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64)]\n",
      "\n",
      "Episode 5 started\n",
      "Initial observation: [  0.  98.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.   0. 138.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [  7.  98.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.   0. 132.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 14.  94.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.   8. 126.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 21.  90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  16. 120.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 28.  90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  16. 114.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 35.  86.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  24. 108.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 42.  82.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  32. 102.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [49. 82.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 32. 96.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [56. 78.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 40. 90.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [63. 74.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 48. 84.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [70. 74.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 48. 78.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [77. 41.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2.  1. 72.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: -0.29325643300798576\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [84. 41.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2.  1. 66.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [91. 37.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2.  9. 60.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [98. 33.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 17. 54.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  33.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  17.  48.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  29.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  25.  42.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  33.  36.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  33.  30.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.043478260869565216\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  21.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  41.  24.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [100.  17.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  49.  18.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   1.   2.]\n",
      "Reward: 0.0026619343389529745\n",
      "\n",
      "Action taken: 1\n",
      "Observation: [65. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 49. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: 0.007246376811594203\n",
      "\n",
      "Action taken: 1\n",
      "Observation: [65. 13.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 57. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: -0.04081632653061224\n",
      "\n",
      "Action taken: 3\n",
      "Observation: [65. 13.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 57. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 3\n",
      "Observation: [65. 13.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 57. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 3\n",
      "Observation: [65. 13.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 57. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 3\n",
      "Observation: [65.  9.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 65. 17.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.]\n",
      "Reward: -0.11081632653061224\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  9.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 65. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.0627536231884058\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 73. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.11081632653061224\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 73. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 73. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 73. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 81. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.11081632653061224\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 81. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 81. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -0.07\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  2. 89. 16.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  0.]\n",
      "Reward: -1.080204081632653\n",
      "\n",
      "Episode finished with total reward: -2.025942028985507\n",
      "Actions taken in episode: [array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(3, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64), array(2, dtype=int64)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WebSocket connection closed.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import websockets\n",
    "import json\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "import numpy as np\n",
    "from ClassPVPOKE import PVPokeEnv\n",
    "from stable_baselines3 import DQN\n",
    "import matplotlib.pyplot as plt\n",
    "import nest_asyncio \n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "# Create and connect environment\n",
    "env = PVPokeEnv(\"ws://localhost:8000/ws\", \"notebook\", \"pvpoke\")\n",
    "asyncio.run(env.connect())\n",
    "\n",
    "# Load pre-trained model\n",
    "model_path = \"dqn_pvpoke_final_deoxys-bastidon\"\n",
    "model = DQN.load(model_path)\n",
    "\n",
    "print(f\"Loaded model from {model_path}\")\n",
    "\n",
    "# Test model performance with debugging\n",
    "rewards = []\n",
    "actions_taken = []\n",
    "observations = []\n",
    "\n",
    "for episode in range(5):\n",
    "    obs, info = env.reset()\n",
    "    print(f\"\\nEpisode {episode + 1} started\")\n",
    "    print(f\"Initial observation: {obs}\")\n",
    "    \n",
    "    \n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    episode_actions = []\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        episode_actions.append(action)\n",
    "        print(f\"\\nAction taken: {action}\")\n",
    "        \n",
    "        obs, reward, done, terminated, info = env.step(action)\n",
    "        print(f\"Observation: {obs}\")\n",
    "        print(f\"Reward: {reward}\")\n",
    "        \n",
    "        total_reward += reward\n",
    "        observations.append(obs)\n",
    "    \n",
    "    print(f\"\\nEpisode finished with total reward: {total_reward}\")\n",
    "    print(f\"Actions taken in episode: {episode_actions}\")\n",
    "    rewards.append(total_reward)\n",
    "    actions_taken.extend(episode_actions)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(rewards, marker='o')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')\n",
    "plt.title('DQN Agent Performance')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(actions_taken, bins=env.action_space.n)\n",
    "plt.xlabel('Actions')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Action Distribution')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Close environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the server.\n",
      "Environment Specifications:\n",
      "Observation Space: Box(0.0, 255.0, (8,), float32)\n",
      "Action Space: Discrete(4)\n",
      "\n",
      "Model Architecture:\n",
      "DQNPolicy(\n",
      "  (q_net): QNetwork(\n",
      "    (features_extractor): FlattenExtractor(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "    (q_net): Sequential(\n",
      "      (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=64, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (q_net_target): QNetwork(\n",
      "    (features_extractor): FlattenExtractor(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "    (q_net): Sequential(\n",
      "      (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=64, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sending message: reset\n",
      "\n",
      "Test Prediction:\n",
      "Observation shape: (8,)\n",
      "Predicted action: 0\n",
      "WebSocket connection closed.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN\n",
    "from ClassPVPOKE import PVPokeEnv\n",
    "\n",
    "# Create environment\n",
    "env = PVPokeEnv(\"ws://localhost:8000/ws\", \"notebook\", \"pvpoke\")\n",
    "asyncio.run(env.connect())\n",
    "\n",
    "# Print environment specs\n",
    "print(\"Environment Specifications:\")\n",
    "print(f\"Observation Space: {env.observation_space}\")\n",
    "print(f\"Action Space: {env.action_space}\")\n",
    "\n",
    "# Load model and print architecture\n",
    "model_path = \"dqn_pvpoke_final_mantine-gligar_optuna\"\n",
    "try:\n",
    "    model = DQN.load(model_path, env=env)\n",
    "    print(\"\\nModel Architecture:\")\n",
    "    print(model.policy)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "\n",
    "# Test single prediction\n",
    "try:\n",
    "    obs, _ = env.reset()\n",
    "    print(\"\\nTest Prediction:\")\n",
    "    print(f\"Observation shape: {obs.shape}\")\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    print(f\"Predicted action: {action}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during prediction: {e}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTUNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-28 11:51:52,284] A new study created in memory with name: no-name-cf637b24-c188-4629-bac1-95c458b508dd\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_31864\\890825868.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_31864\\890825868.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  gamma = trial.suggest_uniform('gamma', 0.9, 0.999)\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_31864\\890825868.py:20: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  exploration_fraction = trial.suggest_uniform('exploration_fraction', 0.1, 0.5)\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_31864\\890825868.py:21: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  exploration_final_eps = trial.suggest_uniform('exploration_final_eps', 0.01, 0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the server.\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=500, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 46.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=1000, episode_reward=-73.60 +/- 7.68\n",
      "Episode length: 35.80 +/- 1.47\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=1500, episode_reward=-76.20 +/- 7.60\n",
      "Episode length: 30.00 +/- 2.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=2000, episode_reward=-83.00 +/- 0.00\n",
      "Episode length: 34.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=2500, episode_reward=-88.00 +/- 0.00\n",
      "Episode length: 31.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=3000, episode_reward=-98.60 +/- 18.80\n",
      "Episode length: 37.00 +/- 2.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=3500, episode_reward=-48.00 +/- 0.00\n",
      "Episode length: 31.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=4000, episode_reward=-67.00 +/- 0.00\n",
      "Episode length: 28.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=4500, episode_reward=-94.00 +/- 0.00\n",
      "Episode length: 33.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=5000, episode_reward=-76.00 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=5500, episode_reward=-42.00 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=6000, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 46.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=6500, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 45.80 +/- 0.40\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=7000, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 46.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=7500, episode_reward=-115.20 +/- 10.78\n",
      "Episode length: 39.60 +/- 2.94\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=8000, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 46.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=8500, episode_reward=-127.00 +/- 0.00\n",
      "Episode length: 31.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=9000, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 46.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=9500, episode_reward=-111.00 +/- 0.00\n",
      "Episode length: 39.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=10000, episode_reward=-102.00 +/- 0.00\n",
      "Episode length: 36.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-28 13:35:13,096] Trial 0 finished with value: -102.0 and parameters: {'learning_rate': 0.0007484760104390964, 'buffer_size': 34306, 'batch_size': 256, 'gamma': 0.9536373641947591, 'exploration_fraction': 0.3608392572521345, 'exploration_final_eps': 0.08839072268939926}. Best is trial 0 with value: -102.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WebSocket connection closed.\n",
      "Connected to the server.\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=500, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 46.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=1000, episode_reward=-115.60 +/- 1.20\n",
      "Episode length: 40.20 +/- 0.40\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=1500, episode_reward=-106.00 +/- 0.00\n",
      "Episode length: 39.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=2000, episode_reward=-109.00 +/- 0.00\n",
      "Episode length: 38.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=2500, episode_reward=-86.60 +/- 4.80\n",
      "Episode length: 22.80 +/- 3.60\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=3000, episode_reward=-77.00 +/- 0.00\n",
      "Episode length: 32.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=3500, episode_reward=-93.00 +/- 0.00\n",
      "Episode length: 33.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=4000, episode_reward=-83.00 +/- 0.00\n",
      "Episode length: 32.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=4500, episode_reward=-124.00 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=5000, episode_reward=-93.00 +/- 19.60\n",
      "Episode length: 38.20 +/- 1.47\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=5500, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 33.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=6000, episode_reward=-51.00 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=6500, episode_reward=-82.00 +/- 14.00\n",
      "Episode length: 25.20 +/- 4.40\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=7000, episode_reward=-89.00 +/- 0.00\n",
      "Episode length: 32.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=7500, episode_reward=-96.00 +/- 0.00\n",
      "Episode length: 34.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=8000, episode_reward=-99.00 +/- 0.00\n",
      "Episode length: 35.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=8500, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 45.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=9000, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 46.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=9500, episode_reward=-77.80 +/- 12.40\n",
      "Episode length: 30.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=10000, episode_reward=-85.80 +/- 12.40\n",
      "Episode length: 35.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-28 15:09:40,186] Trial 1 finished with value: -88.9 and parameters: {'learning_rate': 9.301996110892225e-05, 'buffer_size': 80607, 'batch_size': 32, 'gamma': 0.9713104497888039, 'exploration_fraction': 0.45181342894106047, 'exploration_final_eps': 0.07901715989387353}. Best is trial 1 with value: -88.9.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WebSocket connection closed.\n",
      "Connected to the server.\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=500, episode_reward=-82.00 +/- 0.00\n",
      "Episode length: 20.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=1000, episode_reward=-93.00 +/- 0.00\n",
      "Episode length: 24.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=1500, episode_reward=-78.80 +/- 10.78\n",
      "Episode length: 21.80 +/- 1.47\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=2000, episode_reward=-43.60 +/- 76.25\n",
      "Episode length: 31.00 +/- 6.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=2500, episode_reward=-48.00 +/- 0.00\n",
      "Episode length: 31.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=3000, episode_reward=-88.20 +/- 13.72\n",
      "Episode length: 28.60 +/- 0.49\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=3500, episode_reward=-64.20 +/- 12.40\n",
      "Episode length: 33.20 +/- 0.40\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=4000, episode_reward=-86.00 +/- 0.00\n",
      "Episode length: 32.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=4500, episode_reward=-50.20 +/- 59.60\n",
      "Episode length: 29.00 +/- 4.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=5000, episode_reward=-76.20 +/- 12.40\n",
      "Episode length: 36.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=5500, episode_reward=-75.20 +/- 13.72\n",
      "Episode length: 34.40 +/- 0.49\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=6000, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 46.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=6500, episode_reward=-121.00 +/- 0.00\n",
      "Episode length: 42.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=7000, episode_reward=-99.00 +/- 0.00\n",
      "Episode length: 35.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=7500, episode_reward=-88.80 +/- 12.40\n",
      "Episode length: 35.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=8000, episode_reward=-99.00 +/- 0.00\n",
      "Episode length: 35.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=8500, episode_reward=-127.00 +/- 0.00\n",
      "Episode length: 44.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=9000, episode_reward=-130.00 +/- 0.00\n",
      "Episode length: 45.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=9500, episode_reward=-124.00 +/- 0.00\n",
      "Episode length: 43.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=10000, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 46.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-28 16:38:21,748] Trial 2 finished with value: -133.0 and parameters: {'learning_rate': 0.0005002020345389054, 'buffer_size': 47961, 'batch_size': 256, 'gamma': 0.9748084210129654, 'exploration_fraction': 0.281023740501287, 'exploration_final_eps': 0.05193648699760344}. Best is trial 1 with value: -88.9.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WebSocket connection closed.\n",
      "Connected to the server.\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=500, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 33.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=1000, episode_reward=-109.00 +/- 0.00\n",
      "Episode length: 41.80 +/- 0.40\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=1500, episode_reward=-100.00 +/- 0.00\n",
      "Episode length: 37.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=2000, episode_reward=-84.40 +/- 4.80\n",
      "Episode length: 33.60 +/- 1.20\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=2500, episode_reward=-96.00 +/- 0.00\n",
      "Episode length: 23.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=3000, episode_reward=-96.00 +/- 0.00\n",
      "Episode length: 23.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=3500, episode_reward=-83.00 +/- 0.00\n",
      "Episode length: 32.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=4000, episode_reward=-91.40 +/- 2.94\n",
      "Episode length: 33.40 +/- 0.49\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=4500, episode_reward=-80.00 +/- 0.00\n",
      "Episode length: 31.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=5000, episode_reward=-96.00 +/- 0.00\n",
      "Episode length: 34.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=5500, episode_reward=-67.60 +/- 18.42\n",
      "Episode length: 26.00 +/- 4.15\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=6000, episode_reward=-55.40 +/- 2.80\n",
      "Episode length: 31.40 +/- 0.80\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=6500, episode_reward=-52.00 +/- 56.00\n",
      "Episode length: 28.20 +/- 1.60\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=7000, episode_reward=-115.00 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=7500, episode_reward=-121.00 +/- 0.00\n",
      "Episode length: 42.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=8000, episode_reward=-87.20 +/- 11.60\n",
      "Episode length: 33.20 +/- 0.40\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=8500, episode_reward=-90.00 +/- 0.00\n",
      "Episode length: 32.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=9000, episode_reward=-93.00 +/- 0.00\n",
      "Episode length: 33.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=9500, episode_reward=-56.60 +/- 5.20\n",
      "Episode length: 31.80 +/- 1.60\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=10000, episode_reward=-106.00 +/- 0.00\n",
      "Episode length: 37.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-28 18:20:11,287] Trial 3 finished with value: -106.0 and parameters: {'learning_rate': 0.00010056170468402817, 'buffer_size': 55247, 'batch_size': 32, 'gamma': 0.9955249082006237, 'exploration_fraction': 0.20645174081023848, 'exploration_final_eps': 0.08701723354861225}. Best is trial 1 with value: -88.9.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WebSocket connection closed.\n",
      "Connected to the server.\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=500, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 46.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=1000, episode_reward=-124.00 +/- 0.00\n",
      "Episode length: 43.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=1500, episode_reward=-61.60 +/- 22.76\n",
      "Episode length: 33.00 +/- 1.90\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=2000, episode_reward=-71.00 +/- 19.60\n",
      "Episode length: 23.20 +/- 1.47\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=2500, episode_reward=-79.00 +/- 19.60\n",
      "Episode length: 22.20 +/- 0.98\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=3000, episode_reward=-73.60 +/- 15.19\n",
      "Episode length: 21.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=3500, episode_reward=-78.40 +/- 13.29\n",
      "Episode length: 32.80 +/- 4.40\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=4000, episode_reward=-73.60 +/- 15.19\n",
      "Episode length: 20.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=4500, episode_reward=-54.80 +/- 0.40\n",
      "Episode length: 20.20 +/- 0.40\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=5000, episode_reward=-67.20 +/- 20.00\n",
      "Episode length: 27.40 +/- 5.82\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=5500, episode_reward=-55.60 +/- 2.73\n",
      "Episode length: 20.80 +/- 0.40\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=6000, episode_reward=-56.80 +/- 3.43\n",
      "Episode length: 28.20 +/- 5.88\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=6500, episode_reward=-54.40 +/- 0.49\n",
      "Episode length: 20.60 +/- 0.49\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=7000, episode_reward=-44.40 +/- 4.80\n",
      "Episode length: 29.20 +/- 0.40\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=7500, episode_reward=-54.00 +/- 0.00\n",
      "Episode length: 31.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=8000, episode_reward=-51.00 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=8500, episode_reward=-51.00 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=9000, episode_reward=-51.00 +/- 0.00\n",
      "Episode length: 31.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=9500, episode_reward=-48.60 +/- 1.20\n",
      "Episode length: 29.20 +/- 0.40\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=10000, episode_reward=-48.00 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-28 20:03:57,849] Trial 4 finished with value: -48.0 and parameters: {'learning_rate': 3.2243775007763094e-05, 'buffer_size': 23335, 'batch_size': 32, 'gamma': 0.9425402178303517, 'exploration_fraction': 0.27687288025671425, 'exploration_final_eps': 0.012090955143464824}. Best is trial 4 with value: -48.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WebSocket connection closed.\n",
      "Best hyperparameters:  {'learning_rate': 3.2243775007763094e-05, 'buffer_size': 23335, 'batch_size': 32, 'gamma': 0.9425402178303517, 'exploration_fraction': 0.27687288025671425, 'exploration_final_eps': 0.012090955143464824}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import asyncio\n",
    "import websockets\n",
    "from pydantic import BaseModel\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import json\n",
    "from ClassPVPOKE import PVPokeEnv\n",
    "\n",
    "# Define the objective function\n",
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
    "    buffer_size = trial.suggest_int('buffer_size', 10000, 100000)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128, 256])\n",
    "    gamma = trial.suggest_uniform('gamma', 0.9, 0.999)\n",
    "    exploration_fraction = trial.suggest_uniform('exploration_fraction', 0.1, 0.5)\n",
    "    exploration_final_eps = trial.suggest_uniform('exploration_final_eps', 0.01, 0.1)\n",
    "    \n",
    "    # Create and connect environment\n",
    "    env = PVPokeEnv(\"ws://localhost:8000/ws\", \"notebook\", \"pvpoke\")\n",
    "    asyncio.run(env.connect())\n",
    "    \n",
    "    # Create the DQN model\n",
    "    model = DQN(\n",
    "        \"MlpPolicy\",\n",
    "        env,\n",
    "        learning_rate=learning_rate,\n",
    "        buffer_size=buffer_size,\n",
    "        learning_starts=500,\n",
    "        batch_size=batch_size,\n",
    "        gamma=gamma,\n",
    "        train_freq=4,\n",
    "        gradient_steps=1,\n",
    "        target_update_interval=500,\n",
    "        exploration_fraction=exploration_fraction,\n",
    "        exploration_initial_eps=1.0,\n",
    "        exploration_final_eps=exploration_final_eps,\n",
    "        tensorboard_log=\"./dqn_pvpoke_tensorboard/\"\n",
    "    )\n",
    "    \n",
    "    # Create evaluation callback\n",
    "    eval_callback = EvalCallback(env, best_model_save_path='./logs/',\n",
    "                                 log_path='./logs/', eval_freq=500,\n",
    "                                 deterministic=True, render=False)\n",
    "    \n",
    "    # Train the model\n",
    "    model.learn(total_timesteps=10000, callback=eval_callback)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "    \n",
    "    # Close the environment\n",
    "    env.close()\n",
    "    \n",
    "    return mean_reward\n",
    "\n",
    "# Create the study and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters: \", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "DuplicatedStudyError",
     "evalue": "Another study with name 'dqn_pvpoke_study' already exists. Please specify a different name, or reuse the existing one by setting `load_if_exists` (for Python API) or `--skip-if-exists` flag (for CLI).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1967\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1967\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1968\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:941\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 941\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mexecute(statement, parameters)\n",
      "\u001b[1;31mIntegrityError\u001b[0m: UNIQUE constraint failed: studies.study_name",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\optuna\\storages\\_rdb\\storage.py:272\u001b[0m, in \u001b[0;36mRDBStorage.create_new_study\u001b[1;34m(self, directions, study_name)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 272\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_create_scoped_session\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscoped_session\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\contextlib.py:144\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\optuna\\storages\\_rdb\\storage.py:81\u001b[0m, in \u001b[0;36m_create_scoped_session\u001b[1;34m(scoped_session, ignore_integrity_error)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m session\n\u001b[1;32m---> 81\u001b[0m     \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sqlalchemy_exc\u001b[38;5;241m.\u001b[39mIntegrityError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\sqlalchemy\\orm\\session.py:2028\u001b[0m, in \u001b[0;36mSession.commit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2026\u001b[0m     trans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autobegin_t()\n\u001b[1;32m-> 2028\u001b[0m \u001b[43mtrans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_root\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<string>:2\u001b[0m, in \u001b[0;36mcommit\u001b[1;34m(self, _to_root)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\sqlalchemy\\orm\\state_changes.py:139\u001b[0m, in \u001b[0;36m_StateChange.declare_states.<locals>._go\u001b[1;34m(fn, self, *arg, **kw)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 139\u001b[0m     ret_value \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\sqlalchemy\\orm\\session.py:1313\u001b[0m, in \u001b[0;36mSessionTransaction.commit\u001b[1;34m(self, _to_root)\u001b[0m\n\u001b[0;32m   1312\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expect_state(SessionTransactionState\u001b[38;5;241m.\u001b[39mPREPARED):\n\u001b[1;32m-> 1313\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnested:\n",
      "File \u001b[1;32m<string>:2\u001b[0m, in \u001b[0;36m_prepare_impl\u001b[1;34m(self)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\sqlalchemy\\orm\\state_changes.py:139\u001b[0m, in \u001b[0;36m_StateChange.declare_states.<locals>._go\u001b[1;34m(fn, self, *arg, **kw)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 139\u001b[0m     ret_value \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\sqlalchemy\\orm\\session.py:1288\u001b[0m, in \u001b[0;36mSessionTransaction._prepare_impl\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1288\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\sqlalchemy\\orm\\session.py:4352\u001b[0m, in \u001b[0;36mSession.flush\u001b[1;34m(self, objects)\u001b[0m\n\u001b[0;32m   4351\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flushing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 4352\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flush\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4353\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\sqlalchemy\\orm\\session.py:4487\u001b[0m, in \u001b[0;36mSession._flush\u001b[1;34m(self, objects)\u001b[0m\n\u001b[0;32m   4486\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m-> 4487\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   4488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransaction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_capture_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\sqlalchemy\\orm\\session.py:4448\u001b[0m, in \u001b[0;36mSession._flush\u001b[1;34m(self, objects)\u001b[0m\n\u001b[0;32m   4447\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 4448\u001b[0m     \u001b[43mflush_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4449\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\sqlalchemy\\orm\\unitofwork.py:466\u001b[0m, in \u001b[0;36mUOWTransaction.execute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rec \u001b[38;5;129;01min\u001b[39;00m topological\u001b[38;5;241m.\u001b[39msort(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdependencies, postsort_actions):\n\u001b[1;32m--> 466\u001b[0m     \u001b[43mrec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\sqlalchemy\\orm\\unitofwork.py:642\u001b[0m, in \u001b[0;36mSaveUpdateAll.execute\u001b[1;34m(self, uow)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;129m@util\u001b[39m\u001b[38;5;241m.\u001b[39mpreload_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlalchemy.orm.persistence\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, uow):\n\u001b[1;32m--> 642\u001b[0m     \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreloaded\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morm_persistence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_obj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43muow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstates_for_mapper_hierarchy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43muow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\sqlalchemy\\orm\\persistence.py:93\u001b[0m, in \u001b[0;36msave_obj\u001b[1;34m(base_mapper, states, uowtransaction, single)\u001b[0m\n\u001b[0;32m     85\u001b[0m     _emit_update_statements(\n\u001b[0;32m     86\u001b[0m         base_mapper,\n\u001b[0;32m     87\u001b[0m         uowtransaction,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m         update,\n\u001b[0;32m     91\u001b[0m     )\n\u001b[1;32m---> 93\u001b[0m     \u001b[43m_emit_insert_statements\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_mapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43muowtransaction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43minsert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m _finalize_insert_update_commands(\n\u001b[0;32m    102\u001b[0m     base_mapper,\n\u001b[0;32m    103\u001b[0m     uowtransaction,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    119\u001b[0m     ),\n\u001b[0;32m    120\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\sqlalchemy\\orm\\persistence.py:1233\u001b[0m, in \u001b[0;36m_emit_insert_statements\u001b[1;34m(base_mapper, uowtransaction, mapper, table, insert, bookkeeping, use_orm_insert_stmt, execution_options)\u001b[0m\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1233\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1239\u001b[0m primary_key \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39minserted_primary_key\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1418\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1419\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\sqlalchemy\\sql\\elements.py:515\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[1;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[1;32m--> 515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1640\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[1;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[0;32m   1632\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[0;32m   1633\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[0;32m   1634\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1638\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[0;32m   1639\u001b[0m )\n\u001b[1;32m-> 1640\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1846\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1846\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1986\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1985\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1986\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1987\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1988\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2355\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[0;32m   2354\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   2356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1967\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1967\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1968\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:941\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 941\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mexecute(statement, parameters)\n",
      "\u001b[1;31mIntegrityError\u001b[0m: (sqlite3.IntegrityError) UNIQUE constraint failed: studies.study_name\n[SQL: INSERT INTO studies (study_name) VALUES (?)]\n[parameters: ('dqn_pvpoke_study',)]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDuplicatedStudyError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Crear un nuevo estudio con almacenamiento persistente\u001b[39;00m\n\u001b[0;32m      3\u001b[0m storage_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqlite:///optuna_study.db\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m persistent_study \u001b[38;5;241m=\u001b[39m \u001b[43moptuna\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_study\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdqn_pvpoke_study\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Copiar los datos del estudio existente al nuevo estudio\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m study\u001b[38;5;241m.\u001b[39mtrials:\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\optuna\\_convert_positional_args.py:83\u001b[0m, in \u001b[0;36mconvert_positional_args.<locals>.converter_decorator.<locals>.converter_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() got multiple values for arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduplicated_kwds\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     79\u001b[0m     )\n\u001b[0;32m     81\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate(inferred_kwargs)\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\optuna\\study\\study.py:1265\u001b[0m, in \u001b[0;36mcreate_study\u001b[1;34m(storage, sampler, pruner, study_name, direction, load_if_exists, directions)\u001b[0m\n\u001b[0;32m   1263\u001b[0m storage \u001b[38;5;241m=\u001b[39m storages\u001b[38;5;241m.\u001b[39mget_storage(storage)\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1265\u001b[0m     study_id \u001b[38;5;241m=\u001b[39m \u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_new_study\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirection_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mDuplicatedStudyError:\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m load_if_exists:\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\optuna\\storages\\_cached_storage.py:80\u001b[0m, in \u001b[0;36m_CachedStorage.create_new_study\u001b[1;34m(self, directions, study_name)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_new_study\u001b[39m(\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m, directions: Sequence[StudyDirection], study_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     79\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m---> 80\u001b[0m     study_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_new_study\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstudy_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m     82\u001b[0m         study \u001b[38;5;241m=\u001b[39m _StudyInfo()\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\optuna\\storages\\_rdb\\storage.py:284\u001b[0m, in \u001b[0;36mRDBStorage.create_new_study\u001b[1;34m(self, directions, study_name)\u001b[0m\n\u001b[0;32m    281\u001b[0m         session\u001b[38;5;241m.\u001b[39madd(models\u001b[38;5;241m.\u001b[39mStudyModel(study_name\u001b[38;5;241m=\u001b[39mstudy_name, directions\u001b[38;5;241m=\u001b[39mdirection_models))\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sqlalchemy_exc\u001b[38;5;241m.\u001b[39mIntegrityError:\n\u001b[1;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m optuna\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mDuplicatedStudyError(\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnother study with name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already exists. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease specify a different name, or reuse the existing one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby setting `load_if_exists` (for Python API) or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`--skip-if-exists` flag (for CLI).\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(study_name)\n\u001b[0;32m    289\u001b[0m     )\n\u001b[0;32m    291\u001b[0m _logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA new study created in RDB with name: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(study_name))\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_study_id_from_name(study_name)\n",
      "\u001b[1;31mDuplicatedStudyError\u001b[0m: Another study with name 'dqn_pvpoke_study' already exists. Please specify a different name, or reuse the existing one by setting `load_if_exists` (for Python API) or `--skip-if-exists` flag (for CLI)."
     ]
    }
   ],
   "source": [
    "\n",
    "import optuna\n",
    "# Crear un nuevo estudio con almacenamiento persistente\n",
    "storage_url = 'sqlite:///optuna_study.db'\n",
    "persistent_study = optuna.create_study(study_name='dqn_pvpoke_study', storage=storage_url, direction='maximize')\n",
    "\n",
    "# Copiar los datos del estudio existente al nuevo estudio\n",
    "for trial in study.trials:\n",
    "    persistent_study.add_trial(trial)\n",
    "\n",
    "# Verificar que los datos se han copiado correctamente\n",
    "print(\"Best hyperparameters: \", persistent_study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'learning_rate': 3.2243775007763094e-05, 'buffer_size': 23335, 'batch_size': 32, 'gamma': 0.9425402178303517, 'exploration_fraction': 0.27687288025671425, 'exploration_final_eps': 0.012090955143464824}\n",
      "Best trial value:  -48.0\n",
      "All trials: \n",
      "FrozenTrial(number=0, state=1, values=[-102.0], datetime_start=datetime.datetime(2024, 12, 28, 11, 51, 52, 285777), datetime_complete=datetime.datetime(2024, 12, 28, 13, 35, 13, 95157), params={'learning_rate': 0.0007484760104390964, 'buffer_size': 34306, 'batch_size': 256, 'gamma': 0.9536373641947591, 'exploration_fraction': 0.3608392572521345, 'exploration_final_eps': 0.08839072268939926}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.001, log=True, low=1e-05, step=None), 'buffer_size': IntDistribution(high=100000, log=False, low=10000, step=1), 'batch_size': CategoricalDistribution(choices=(32, 64, 128, 256)), 'gamma': FloatDistribution(high=0.999, log=False, low=0.9, step=None), 'exploration_fraction': FloatDistribution(high=0.5, log=False, low=0.1, step=None), 'exploration_final_eps': FloatDistribution(high=0.1, log=False, low=0.01, step=None)}, trial_id=1, value=None)\n",
      "FrozenTrial(number=1, state=1, values=[-88.9], datetime_start=datetime.datetime(2024, 12, 28, 13, 35, 13, 97148), datetime_complete=datetime.datetime(2024, 12, 28, 15, 9, 40, 185029), params={'learning_rate': 9.301996110892225e-05, 'buffer_size': 80607, 'batch_size': 32, 'gamma': 0.9713104497888039, 'exploration_fraction': 0.45181342894106047, 'exploration_final_eps': 0.07901715989387353}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.001, log=True, low=1e-05, step=None), 'buffer_size': IntDistribution(high=100000, log=False, low=10000, step=1), 'batch_size': CategoricalDistribution(choices=(32, 64, 128, 256)), 'gamma': FloatDistribution(high=0.999, log=False, low=0.9, step=None), 'exploration_fraction': FloatDistribution(high=0.5, log=False, low=0.1, step=None), 'exploration_final_eps': FloatDistribution(high=0.1, log=False, low=0.01, step=None)}, trial_id=2, value=None)\n",
      "FrozenTrial(number=2, state=1, values=[-133.0], datetime_start=datetime.datetime(2024, 12, 28, 15, 9, 40, 187042), datetime_complete=datetime.datetime(2024, 12, 28, 16, 38, 21, 747302), params={'learning_rate': 0.0005002020345389054, 'buffer_size': 47961, 'batch_size': 256, 'gamma': 0.9748084210129654, 'exploration_fraction': 0.281023740501287, 'exploration_final_eps': 0.05193648699760344}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.001, log=True, low=1e-05, step=None), 'buffer_size': IntDistribution(high=100000, log=False, low=10000, step=1), 'batch_size': CategoricalDistribution(choices=(32, 64, 128, 256)), 'gamma': FloatDistribution(high=0.999, log=False, low=0.9, step=None), 'exploration_fraction': FloatDistribution(high=0.5, log=False, low=0.1, step=None), 'exploration_final_eps': FloatDistribution(high=0.1, log=False, low=0.01, step=None)}, trial_id=3, value=None)\n",
      "FrozenTrial(number=3, state=1, values=[-106.0], datetime_start=datetime.datetime(2024, 12, 28, 16, 38, 21, 749304), datetime_complete=datetime.datetime(2024, 12, 28, 18, 20, 11, 286883), params={'learning_rate': 0.00010056170468402817, 'buffer_size': 55247, 'batch_size': 32, 'gamma': 0.9955249082006237, 'exploration_fraction': 0.20645174081023848, 'exploration_final_eps': 0.08701723354861225}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.001, log=True, low=1e-05, step=None), 'buffer_size': IntDistribution(high=100000, log=False, low=10000, step=1), 'batch_size': CategoricalDistribution(choices=(32, 64, 128, 256)), 'gamma': FloatDistribution(high=0.999, log=False, low=0.9, step=None), 'exploration_fraction': FloatDistribution(high=0.5, log=False, low=0.1, step=None), 'exploration_final_eps': FloatDistribution(high=0.1, log=False, low=0.01, step=None)}, trial_id=4, value=None)\n",
      "FrozenTrial(number=4, state=1, values=[-48.0], datetime_start=datetime.datetime(2024, 12, 28, 18, 20, 11, 288885), datetime_complete=datetime.datetime(2024, 12, 28, 20, 3, 57, 848554), params={'learning_rate': 3.2243775007763094e-05, 'buffer_size': 23335, 'batch_size': 32, 'gamma': 0.9425402178303517, 'exploration_fraction': 0.27687288025671425, 'exploration_final_eps': 0.012090955143464824}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.001, log=True, low=1e-05, step=None), 'buffer_size': IntDistribution(high=100000, log=False, low=10000, step=1), 'batch_size': CategoricalDistribution(choices=(32, 64, 128, 256)), 'gamma': FloatDistribution(high=0.999, log=False, low=0.9, step=None), 'exploration_fraction': FloatDistribution(high=0.5, log=False, low=0.1, step=None), 'exploration_final_eps': FloatDistribution(high=0.1, log=False, low=0.01, step=None)}, trial_id=5, value=None)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\optuna\\visualization\\_plotly_imports.py:7\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m try_import() \u001b[38;5;28;01mas\u001b[39;00m _imports:\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m plotly_version\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(trial)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Generar gráficos\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[43moptuna\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_optimization_history\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     20\u001b[0m optuna\u001b[38;5;241m.\u001b[39mvisualization\u001b[38;5;241m.\u001b[39mplot_param_importances(study)\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     21\u001b[0m optuna\u001b[38;5;241m.\u001b[39mvisualization\u001b[38;5;241m.\u001b[39mplot_parallel_coordinate(study)\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\optuna\\visualization\\_optimization_history.py:200\u001b[0m, in \u001b[0;36mplot_optimization_history\u001b[1;34m(study, target, target_name, error_bar)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_optimization_history\u001b[39m(\n\u001b[0;32m    173\u001b[0m     study: Study \u001b[38;5;241m|\u001b[39m Sequence[Study],\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m     error_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    178\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgo.Figure\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    179\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Plot optimization history of all trials in a study.\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \n\u001b[0;32m    181\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03m        A :class:`plotly.graph_objects.Figure` object.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m     \u001b[43m_imports\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m     info_list \u001b[38;5;241m=\u001b[39m _get_optimization_history_info_list(study, target, target_name, error_bar)\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_optimization_history_plot(info_list, target_name)\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\optuna\\_imports.py:95\u001b[0m, in \u001b[0;36m_DeferredImportExceptionContextManager.check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deferred \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     exc_value, message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deferred\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc_value\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'."
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "# Cargar el estudio desde el almacenamiento persistente\n",
    "storage_url = 'sqlite:///optuna_study.db'\n",
    "study = optuna.load_study(study_name='dqn_pvpoke_study', storage=storage_url)\n",
    "\n",
    "# Ver los mejores hiperparámetros\n",
    "print(\"Best hyperparameters: \", study.best_params)\n",
    "\n",
    "# Ver el valor de la mejor prueba\n",
    "print(\"Best trial value: \", study.best_value)\n",
    "\n",
    "# Ver el historial de pruebas\n",
    "print(\"All trials: \")\n",
    "for trial in study.trials:\n",
    "    print(trial)\n",
    "\n",
    "# Generar gráficos\n",
    "optuna.visualization.plot_optimization_history(study).show()\n",
    "optuna.visualization.plot_param_importances(study).show()\n",
    "optuna.visualization.plot_parallel_coordinate(study).show()\n",
    "optuna.visualization.plot_slice(study).show()\n",
    "optuna.visualization.plot_contour(study).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
