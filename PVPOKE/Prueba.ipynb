{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries and Environment\n",
    "Import Stable Baselines3, the custom PVPokeEnv, and other required libraries. Configure environment variables and connect to the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the server.\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "WebSocket connection closed.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import websockets\n",
    "from pydantic import BaseModel\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import json\n",
    "from ClassPVPOKE import PVPokeEnv\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "# Create an instance of the environment and connect to the server\n",
    "env = PVPokeEnv(\"ws://localhost:8000/ws\", \"notebook\", \"pvpoke\")\n",
    "env.loop.run_until_complete(env.connect())\n",
    "\n",
    "# Check if the environment follows the Gym API\n",
    "check_env(env)\n",
    "\n",
    "# Close the environment connection\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Configure the Agent PPO\n",
    "Create and configure a Stable Baselines3 agent (like PPO or DQN) with appropriate hyperparameters for the PVPoke environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the server.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696db5f75dcc41c5b16933eecb4e2bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from ClassPVPOKE import PVPokeEnv\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "\n",
    "env = PVPokeEnv(\"ws://localhost:8000/ws\", \"notebook\", \"pvpoke\")\n",
    "env.loop.run_until_complete(env.connect())\n",
    "\n",
    "model = PPO(\n",
    "    policy=\"MlpPolicy\",\n",
    "    env=env,\n",
    "    learning_rate=3e-4,\n",
    "    n_steps=128,\n",
    "    batch_size=64,\n",
    "    n_epochs=10,\n",
    "    gamma=0.99,\n",
    "    gae_lambda=0.95,\n",
    "    clip_range=0.2,\n",
    "    ent_coef=0.01,\n",
    "    vf_coef=0.5,\n",
    "    max_grad_norm=0.5,\n",
    "    tensorboard_log=\"./ppo_pvpoke_tensorboard/mandibuzz-Annihilape\",\n",
    "    policy_kwargs={\"net_arch\": [128, 128]}  \n",
    ")\n",
    "\n",
    "# Guardar checkpoints regularmente\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "    save_freq=5000, \n",
    "    save_path='./models/ppo/mandibuzz-Annihilape', \n",
    "    name_prefix='ppo_pvpoke_1v1'\n",
    ")\n",
    "\n",
    "# Entrenar con los parámetros ajustados\n",
    "model.learn(total_timesteps=200000, callback=checkpoint_callback, progress_bar=True)\n",
    "\n",
    "# Guardar el modelo final\n",
    "model.save(\"ppo_pvpoke_final_mandibuzz-Annihilape\")\n",
    "\n",
    "# Close the environment connection\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the server.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517cde8ce93948819d5f1bc376b0c1e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import asyncio\n",
    "import websockets\n",
    "from pydantic import BaseModel\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import json\n",
    "from ClassPVPOKE import PVPokeEnv\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Crear y conectar el entorno\n",
    "env = PVPokeEnv(\"ws://localhost:8000/ws\", \"notebook\", \"pvpoke\")\n",
    "env.loop.run_until_complete(env.connect())\n",
    "\n",
    "\n",
    "\n",
    "# ✅ Crear el modelo DQN con la red personalizada\n",
    "model = DQN(\n",
    "    policy=\"MlpPolicy\",\n",
    "    env=env,\n",
    "    learning_rate=1e-3,              # Aprendizaje ajustado para 1v1\n",
    "    buffer_size=50000,               # Tamaño de buffer aumentado para estabilidad\n",
    "    learning_starts=1000,            # Más pasos antes de comenzar el aprendizaje\n",
    "    batch_size=128,                  # Tamaño de batch ideal para 1v1\n",
    "    gamma=0.99,                      # Factor de descuento a largo plazo\n",
    "    train_freq=4,                    # Actualización cada 4 pasos\n",
    "    gradient_steps=1,                # Un paso de gradiente por actualización\n",
    "    target_update_interval=1000,     # Actualización del target más frecuente\n",
    "    exploration_fraction=0.1,        \n",
    "    exploration_initial_eps=1.0,     \n",
    "    exploration_final_eps=0.05,      \n",
    "    tensorboard_log=\"./dqn_pvpoke_tensorboard/mandibuzz-Annihilape\",\n",
    "    policy_kwargs={\"net_arch\": [128, 128]}  # ✅ Especificando la red de 128-128\n",
    ")\n",
    "\n",
    "# ✅ Callback para guardar checkpoints cada 5000 steps\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "    save_freq=5000, \n",
    "    save_path='./models/dqn/mandibuzz-Annihilape', \n",
    "    name_prefix='dqn_pvpoke'\n",
    ")\n",
    "\n",
    "# ✅ Entrenar el modelo con los nuevos ajustes\n",
    "model.learn(total_timesteps=200000, callback=checkpoint_callback, progress_bar=True)\n",
    "\n",
    "# ✅ Guardar el modelo final\n",
    "model.save(\"dqn_pvpoke_final_mandibuzz-Annihilape\")\n",
    "\n",
    "# Cerrar el entorno al finalizar\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenar DQN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the server.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 123] El nombre de archivo, el nombre de directorio o la sintaxis de la etiqueta del volumen no son correctos: './models/dqn/Skar-TA-SA-BRB-Swampert-MS-HC-SW-Umbreon-SN-LR-FP-Trev-SC-SeB-SD-Vigp-Co-BS-RS-Dewgong-Is-IW-DR\"'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 41\u001b[0m\n\u001b[0;32m     36\u001b[0m checkpoint_callback \u001b[38;5;241m=\u001b[39m CheckpointCallback(save_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m, \n\u001b[0;32m     37\u001b[0m                                          save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./models/dqn/Skar-TA-SA-BRB-Swampert-MS-HC-SW-Umbreon-SN-LR-FP-Trev-SC-SeB-SD-Vigp-Co-BS-RS-Dewgong-Is-IW-DR\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     38\u001b[0m                                          name_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdqn_pvpoke\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Train the agent\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Save final model\u001b[39;00m\n\u001b[0;32m     44\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdqn_pvpoke_final_Skar-TA-SA-BRB-Swampert-MS-HC-SW-Umbreon-SN-LR-FP-Trev-SC-SeB-SD-Vigp-Co-BS-RS-Dewgong-Is-IW-DR\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\stable_baselines3\\dqn\\dqn.py:267\u001b[0m, in \u001b[0;36mDQN.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfDQN,\n\u001b[0;32m    260\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    266\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfDQN:\n\u001b[1;32m--> 267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:314\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfOffPolicyAlgorithm,\n\u001b[0;32m    307\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    312\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    313\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfOffPolicyAlgorithm:\n\u001b[1;32m--> 314\u001b[0m     total_timesteps, callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_learn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m     callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must set the environment before calling learn()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:297\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm._setup_learn\u001b[1;34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_noise \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mnum_envs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_noise, VectorizedActionNoise)\n\u001b[0;32m    294\u001b[0m ):\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_noise \u001b[38;5;241m=\u001b[39m VectorizedActionNoise(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_noise, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mnum_envs)\n\u001b[1;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_learn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\stable_baselines3\\common\\base_class.py:434\u001b[0m, in \u001b[0;36mBaseAlgorithm._setup_learn\u001b[1;34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mconfigure_logger(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensorboard_log, tb_log_name, reset_num_timesteps)\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# Create eval callback if needed\u001b[39;00m\n\u001b[1;32m--> 434\u001b[0m callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_timesteps, callback\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\stable_baselines3\\common\\base_class.py:380\u001b[0m, in \u001b[0;36mBaseAlgorithm._init_callback\u001b[1;34m(self, callback, progress_bar)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m progress_bar:\n\u001b[0;32m    378\u001b[0m     callback \u001b[38;5;241m=\u001b[39m CallbackList([callback, ProgressBarCallback()])\n\u001b[1;32m--> 380\u001b[0m \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m callback\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\stable_baselines3\\common\\callbacks.py:73\u001b[0m, in \u001b[0;36mBaseCallback.init_callback\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03mInitialize the callback by saving references to the\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03mRL model and the training environment for convenience.\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\stable_baselines3\\common\\callbacks.py:286\u001b[0m, in \u001b[0;36mCheckpointCallback._init_callback\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_init_callback\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;66;03m# Create folder if needed\u001b[39;00m\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 286\u001b[0m         \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 123] El nombre de archivo, el nombre de directorio o la sintaxis de la etiqueta del volumen no son correctos: './models/dqn/Skar-TA-SA-BRB-Swampert-MS-HC-SW-Umbreon-SN-LR-FP-Trev-SC-SeB-SD-Vigp-Co-BS-RS-Dewgong-Is-IW-DR\"'"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import asyncio\n",
    "import websockets\n",
    "from pydantic import BaseModel\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import json\n",
    "from ClassPVPOKE import PVPokeEnv\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create and connect environment\n",
    "env = PVPokeEnv(\"ws://localhost:8000/ws\", \"notebook\", \"pvpoke\")\n",
    "env.loop.run_until_complete(env.connect())\n",
    "\n",
    "# Create DQN agent with appropriate hyperparameters\n",
    "model = DQN(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    learning_rate=1e-3,  # Aumentar la tasa de aprendizaje\n",
    "    buffer_size=50000,  # Reducir el tamaño del buffer\n",
    "    learning_starts=100,  # Reducir el número de pasos antes de empezar a aprender\n",
    "    batch_size=128,  # Reducir el tamaño del batch\n",
    "    gamma=0.99,\n",
    "    train_freq=4,\n",
    "    gradient_steps=1,\n",
    "    target_update_interval=1000,  # Reducir el intervalo de actualización del objetivo\n",
    "    exploration_fraction=0.1,\n",
    "    exploration_initial_eps=1,\n",
    "    exploration_final_eps=0.05,    \n",
    "    tensorboard_log=\"./dqn_pvpoke_tensorboard/3v3/Skar-TA-SA-BRB-Swampert-MS-HC-SW-Umbreon-SN-LR-FP-Trev-SC-SeB-SD-Vigp-Co-BS-RS-Dewgong-Is-IW-DR\"\n",
    ")\n",
    "# Create checkpoint callback\n",
    "checkpoint_callback = CheckpointCallback(save_freq=5000, \n",
    "                                         save_path='./models/dqn/3v3/Skar-TA-SA-BRB-Swampert-MS-HC-SW-Umbreon-SN-LR-FP-Trev-SC-SeB-SD-Vigp-Co-BS-RS-Dewgong-Is-IW-DR\"',\n",
    "                                         name_prefix='dqn_pvpoke')\n",
    "\n",
    "# Train the agent\n",
    "model.learn(total_timesteps = 200000, callback=checkpoint_callback, progress_bar=False)\n",
    "\n",
    "# Save final model\n",
    "model.save(\"dqn_pvpoke_final_Skar-TA-SA-BRB-Swampert-MS-HC-SW-Umbreon-SN-LR-FP-Trev-SC-SeB-SD-Vigp-Co-BS-RS-Dewgong-Is-IW-DR\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probar el agente en un episodio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the server.\n",
      "Loaded model from C:\\pvpokeDRL\\pvpoke\\PVPOKE\\dqn_pvpoke_final_mantine-gligar.zip\n",
      "\n",
      "Episode 1 started\n",
      "Initial observation: [  0. 122.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.   0. 130.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.]\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [  8. 119.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.   8. 127.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.]\n",
      "Reward: -0.0015132408575031508\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 16. 116.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  16. 124.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.]\n",
      "Reward: -0.0015132408575031508\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 24. 113.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  24. 121.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.]\n",
      "Reward: -0.0015132408575031508\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 32. 110.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  32. 118.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.]\n",
      "Reward: -0.0015132408575031508\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 40. 107.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  40. 115.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.]\n",
      "Reward: -0.0015132408575031508\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 40. 107.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  40. 115.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.]\n",
      "Reward: 0\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 48.  78.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.   0. 112.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.]\n",
      "Reward: -0.2146279949558638\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 56.  75.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.   8. 109.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.]\n",
      "Reward: -0.0015132408575031508\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 64.  72.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  16. 106.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.]\n",
      "Reward: -0.0015132408575031508\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 72.  69.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  24. 103.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.]\n",
      "Reward: -0.0015132408575031508\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [ 80.  66.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.  32. 100.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.   2.]\n",
      "Reward: -0.0015132408575031508\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [88. 63.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 40. 97.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  2.]\n",
      "Reward: -0.0015132408575031508\n",
      "\n",
      "Action taken: 1\n",
      "Observation: [88. 63.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 40. 97.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  2.]\n",
      "Reward: 0\n",
      "\n",
      "Action taken: 1\n",
      "Observation: [48. 63.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 40. 96.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  1.]\n",
      "Reward: 0.007692307692307693\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [48. 34.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2.  0. 96.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  1.]\n",
      "Reward: -0.23770491803278687\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [56. 31.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2.  8. 93.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  1.]\n",
      "Reward: -0.0015132408575031508\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [64. 28.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 16. 90.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  1.]\n",
      "Reward: -0.0015132408575031508\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [72. 25.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 24. 87.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  1.]\n",
      "Reward: -0.0015132408575031508\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [80. 22.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 32. 84.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  1.]\n",
      "Reward: -0.0015132408575031508\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [88. 19.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  2. 40. 81.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  1.]\n",
      "Reward: -0.0015132408575031508\n",
      "\n",
      "Action taken: 3\n",
      "Observation: [88. 18.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  1.  0. 81.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  1.]\n",
      "Reward: -0.10819672131147541\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [96. 15.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  1.  8. 78.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  1.]\n",
      "Reward: -0.0015132408575031508\n",
      "\n",
      "Action taken: 1\n",
      "Observation: [96. 12.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  1. 16. 78.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  1.]\n",
      "Reward: -0.02459016393442623\n",
      "\n",
      "Action taken: 0\n",
      "Observation: [56. 12.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  1. 16. 77.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "Reward: 0.007692307692307693\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [56.  9.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  1. 24. 77.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "Reward: -0.02459016393442623\n",
      "\n",
      "Action taken: 2\n",
      "Observation: [ 1.  9.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  1. 24.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "Reward: 1.4923076923076923\n",
      "\n",
      "Episode finished with total reward: 0.8737704918032787\n",
      "Actions taken in episode: [array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(0, dtype=int64), array(3, dtype=int64), array(0, dtype=int64), array(1, dtype=int64), array(0, dtype=int64), array(2, dtype=int64), array(2, dtype=int64)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WebSocket connection closed.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import websockets\n",
    "import json\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "import numpy as np\n",
    "from ClassPVPOKE import PVPokeEnv\n",
    "from stable_baselines3 import DQN\n",
    "import matplotlib.pyplot as plt\n",
    "import nest_asyncio \n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "# Create and connect environment\n",
    "env = PVPokeEnv(\"ws://localhost:8000/ws\", \"notebook\", \"pvpoke\")\n",
    "env.loop.run_until_complete(env.connect())\n",
    "\n",
    "# Load pre-trained model\n",
    "model_path = \"C:\\pvpokeDRL\\pvpoke\\PVPOKE\\dqn_pvpoke_final_mantine-gligar.zip\"\n",
    "model = DQN.load(model_path)\n",
    "\n",
    "#model_path  = \"C:\\pvpokeDRL\\pvpoke\\PVPOKE\\models\\ppo\\mandibuzz-Annihilape\\ppo_pvpoke_1v1_140000_steps.zip\"\n",
    "#model = PPO.load(model_path)\n",
    "print(f\"Loaded model from {model_path}\")\n",
    "\n",
    "# Test model performance with debugging\n",
    "rewards = []\n",
    "actions_taken = []\n",
    "observations = []\n",
    "\n",
    "for episode in range(1):\n",
    "    obs, info = env.reset()\n",
    "    print(f\"\\nEpisode {episode + 1} started\")\n",
    "    print(f\"Initial observation: {obs}\")\n",
    "    \n",
    "    \n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    episode_actions = []\n",
    "    \n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        episode_actions.append(action)\n",
    "        print(f\"\\nAction taken: {action}\")\n",
    "        \n",
    "        obs, reward, done, terminated, info = env.step(action)\n",
    "        print(f\"Observation: {obs}\")\n",
    "        print(f\"Reward: {reward}\")\n",
    "        \n",
    "        total_reward += reward\n",
    "        observations.append(obs)\n",
    "    \n",
    "    print(f\"\\nEpisode finished with total reward: {total_reward}\")\n",
    "    print(f\"Actions taken in episode: {episode_actions}\")\n",
    "    rewards.append(total_reward)\n",
    "    actions_taken.extend(episode_actions)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(rewards, marker='o')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')\n",
    "plt.title('DQN Agent Performance')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(actions_taken, bins=np.arange(env.action_space.n + 1) - 0.5, align=\"mid\", rwidth=0.8)\n",
    "plt.xticks(np.arange(env.action_space.n))\n",
    "plt.xlabel('Actions')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Action Distribution')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Close environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the server.\n",
      "Environment Specifications:\n",
      "Observation Space: Box(0.0, 255.0, (8,), float32)\n",
      "Action Space: Discrete(4)\n",
      "\n",
      "Model Architecture:\n",
      "DQNPolicy(\n",
      "  (q_net): QNetwork(\n",
      "    (features_extractor): FlattenExtractor(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "    (q_net): Sequential(\n",
      "      (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=64, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (q_net_target): QNetwork(\n",
      "    (features_extractor): FlattenExtractor(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "    (q_net): Sequential(\n",
      "      (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=64, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sending message: reset\n",
      "\n",
      "Test Prediction:\n",
      "Observation shape: (8,)\n",
      "Predicted action: 0\n",
      "WebSocket connection closed.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN\n",
    "from ClassPVPOKE import PVPokeEnv\n",
    "\n",
    "# Create environment\n",
    "env = PVPokeEnv(\"ws://localhost:8000/ws\", \"notebook\", \"pvpoke\")\n",
    "env.loop.run_until_complete(env.connect())\n",
    "\n",
    "# Print environment specs\n",
    "print(\"Environment Specifications:\")\n",
    "print(f\"Observation Space: {env.observation_space}\")\n",
    "print(f\"Action Space: {env.action_space}\")\n",
    "\n",
    "# Load model and print architecture\n",
    "model_path = \"dqn_pvpoke_final_mantine-gligar_optuna\"\n",
    "try:\n",
    "    model = DQN.load(model_path, env=env)\n",
    "    print(\"\\nModel Architecture:\")\n",
    "    print(model.policy)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "\n",
    "# Test single prediction\n",
    "try:\n",
    "    obs, _ = env.reset()\n",
    "    print(\"\\nTest Prediction:\")\n",
    "    print(f\"Observation shape: {obs.shape}\")\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    print(f\"Predicted action: {action}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during prediction: {e}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTUNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-28 11:51:52,284] A new study created in memory with name: no-name-cf637b24-c188-4629-bac1-95c458b508dd\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_31864\\890825868.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_31864\\890825868.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  gamma = trial.suggest_uniform('gamma', 0.9, 0.999)\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_31864\\890825868.py:20: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  exploration_fraction = trial.suggest_uniform('exploration_fraction', 0.1, 0.5)\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_31864\\890825868.py:21: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  exploration_final_eps = trial.suggest_uniform('exploration_final_eps', 0.01, 0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the server.\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samue\\miniconda3\\envs\\gym\\Lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=500, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 46.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=1000, episode_reward=-73.60 +/- 7.68\n",
      "Episode length: 35.80 +/- 1.47\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=1500, episode_reward=-76.20 +/- 7.60\n",
      "Episode length: 30.00 +/- 2.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=2000, episode_reward=-83.00 +/- 0.00\n",
      "Episode length: 34.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=2500, episode_reward=-88.00 +/- 0.00\n",
      "Episode length: 31.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=3000, episode_reward=-98.60 +/- 18.80\n",
      "Episode length: 37.00 +/- 2.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=3500, episode_reward=-48.00 +/- 0.00\n",
      "Episode length: 31.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=4000, episode_reward=-67.00 +/- 0.00\n",
      "Episode length: 28.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=4500, episode_reward=-94.00 +/- 0.00\n",
      "Episode length: 33.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=5000, episode_reward=-76.00 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=5500, episode_reward=-42.00 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=6000, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 46.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=6500, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 45.80 +/- 0.40\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=7000, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 46.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=7500, episode_reward=-115.20 +/- 10.78\n",
      "Episode length: 39.60 +/- 2.94\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=8000, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 46.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=8500, episode_reward=-127.00 +/- 0.00\n",
      "Episode length: 31.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=9000, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 46.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=9500, episode_reward=-111.00 +/- 0.00\n",
      "Episode length: 39.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=10000, episode_reward=-102.00 +/- 0.00\n",
      "Episode length: 36.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-28 13:35:13,096] Trial 0 finished with value: -102.0 and parameters: {'learning_rate': 0.0007484760104390964, 'buffer_size': 34306, 'batch_size': 256, 'gamma': 0.9536373641947591, 'exploration_fraction': 0.3608392572521345, 'exploration_final_eps': 0.08839072268939926}. Best is trial 0 with value: -102.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WebSocket connection closed.\n",
      "Connected to the server.\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=500, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 46.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=1000, episode_reward=-115.60 +/- 1.20\n",
      "Episode length: 40.20 +/- 0.40\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=1500, episode_reward=-106.00 +/- 0.00\n",
      "Episode length: 39.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=2000, episode_reward=-109.00 +/- 0.00\n",
      "Episode length: 38.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=2500, episode_reward=-86.60 +/- 4.80\n",
      "Episode length: 22.80 +/- 3.60\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=3000, episode_reward=-77.00 +/- 0.00\n",
      "Episode length: 32.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=3500, episode_reward=-93.00 +/- 0.00\n",
      "Episode length: 33.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=4000, episode_reward=-83.00 +/- 0.00\n",
      "Episode length: 32.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=4500, episode_reward=-124.00 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=5000, episode_reward=-93.00 +/- 19.60\n",
      "Episode length: 38.20 +/- 1.47\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=5500, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 33.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=6000, episode_reward=-51.00 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=6500, episode_reward=-82.00 +/- 14.00\n",
      "Episode length: 25.20 +/- 4.40\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=7000, episode_reward=-89.00 +/- 0.00\n",
      "Episode length: 32.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=7500, episode_reward=-96.00 +/- 0.00\n",
      "Episode length: 34.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=8000, episode_reward=-99.00 +/- 0.00\n",
      "Episode length: 35.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=8500, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 45.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=9000, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 46.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=9500, episode_reward=-77.80 +/- 12.40\n",
      "Episode length: 30.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=10000, episode_reward=-85.80 +/- 12.40\n",
      "Episode length: 35.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-28 15:09:40,186] Trial 1 finished with value: -88.9 and parameters: {'learning_rate': 9.301996110892225e-05, 'buffer_size': 80607, 'batch_size': 32, 'gamma': 0.9713104497888039, 'exploration_fraction': 0.45181342894106047, 'exploration_final_eps': 0.07901715989387353}. Best is trial 1 with value: -88.9.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WebSocket connection closed.\n",
      "Connected to the server.\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=500, episode_reward=-82.00 +/- 0.00\n",
      "Episode length: 20.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=1000, episode_reward=-93.00 +/- 0.00\n",
      "Episode length: 24.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=1500, episode_reward=-78.80 +/- 10.78\n",
      "Episode length: 21.80 +/- 1.47\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=2000, episode_reward=-43.60 +/- 76.25\n",
      "Episode length: 31.00 +/- 6.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=2500, episode_reward=-48.00 +/- 0.00\n",
      "Episode length: 31.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=3000, episode_reward=-88.20 +/- 13.72\n",
      "Episode length: 28.60 +/- 0.49\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=3500, episode_reward=-64.20 +/- 12.40\n",
      "Episode length: 33.20 +/- 0.40\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=4000, episode_reward=-86.00 +/- 0.00\n",
      "Episode length: 32.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=4500, episode_reward=-50.20 +/- 59.60\n",
      "Episode length: 29.00 +/- 4.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=5000, episode_reward=-76.20 +/- 12.40\n",
      "Episode length: 36.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=5500, episode_reward=-75.20 +/- 13.72\n",
      "Episode length: 34.40 +/- 0.49\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=6000, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 46.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=6500, episode_reward=-121.00 +/- 0.00\n",
      "Episode length: 42.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=7000, episode_reward=-99.00 +/- 0.00\n",
      "Episode length: 35.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=7500, episode_reward=-88.80 +/- 12.40\n",
      "Episode length: 35.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=8000, episode_reward=-99.00 +/- 0.00\n",
      "Episode length: 35.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=8500, episode_reward=-127.00 +/- 0.00\n",
      "Episode length: 44.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=9000, episode_reward=-130.00 +/- 0.00\n",
      "Episode length: 45.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=9500, episode_reward=-124.00 +/- 0.00\n",
      "Episode length: 43.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=10000, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 46.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-28 16:38:21,748] Trial 2 finished with value: -133.0 and parameters: {'learning_rate': 0.0005002020345389054, 'buffer_size': 47961, 'batch_size': 256, 'gamma': 0.9748084210129654, 'exploration_fraction': 0.281023740501287, 'exploration_final_eps': 0.05193648699760344}. Best is trial 1 with value: -88.9.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WebSocket connection closed.\n",
      "Connected to the server.\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=500, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 33.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=1000, episode_reward=-109.00 +/- 0.00\n",
      "Episode length: 41.80 +/- 0.40\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=1500, episode_reward=-100.00 +/- 0.00\n",
      "Episode length: 37.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=2000, episode_reward=-84.40 +/- 4.80\n",
      "Episode length: 33.60 +/- 1.20\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=2500, episode_reward=-96.00 +/- 0.00\n",
      "Episode length: 23.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=3000, episode_reward=-96.00 +/- 0.00\n",
      "Episode length: 23.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=3500, episode_reward=-83.00 +/- 0.00\n",
      "Episode length: 32.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=4000, episode_reward=-91.40 +/- 2.94\n",
      "Episode length: 33.40 +/- 0.49\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=4500, episode_reward=-80.00 +/- 0.00\n",
      "Episode length: 31.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=5000, episode_reward=-96.00 +/- 0.00\n",
      "Episode length: 34.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=5500, episode_reward=-67.60 +/- 18.42\n",
      "Episode length: 26.00 +/- 4.15\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=6000, episode_reward=-55.40 +/- 2.80\n",
      "Episode length: 31.40 +/- 0.80\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=6500, episode_reward=-52.00 +/- 56.00\n",
      "Episode length: 28.20 +/- 1.60\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=7000, episode_reward=-115.00 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=7500, episode_reward=-121.00 +/- 0.00\n",
      "Episode length: 42.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=8000, episode_reward=-87.20 +/- 11.60\n",
      "Episode length: 33.20 +/- 0.40\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=8500, episode_reward=-90.00 +/- 0.00\n",
      "Episode length: 32.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=9000, episode_reward=-93.00 +/- 0.00\n",
      "Episode length: 33.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=9500, episode_reward=-56.60 +/- 5.20\n",
      "Episode length: 31.80 +/- 1.60\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=10000, episode_reward=-106.00 +/- 0.00\n",
      "Episode length: 37.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-28 18:20:11,287] Trial 3 finished with value: -106.0 and parameters: {'learning_rate': 0.00010056170468402817, 'buffer_size': 55247, 'batch_size': 32, 'gamma': 0.9955249082006237, 'exploration_fraction': 0.20645174081023848, 'exploration_final_eps': 0.08701723354861225}. Best is trial 1 with value: -88.9.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WebSocket connection closed.\n",
      "Connected to the server.\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=500, episode_reward=-133.00 +/- 0.00\n",
      "Episode length: 46.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=1000, episode_reward=-124.00 +/- 0.00\n",
      "Episode length: 43.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=1500, episode_reward=-61.60 +/- 22.76\n",
      "Episode length: 33.00 +/- 1.90\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=2000, episode_reward=-71.00 +/- 19.60\n",
      "Episode length: 23.20 +/- 1.47\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=2500, episode_reward=-79.00 +/- 19.60\n",
      "Episode length: 22.20 +/- 0.98\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=3000, episode_reward=-73.60 +/- 15.19\n",
      "Episode length: 21.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=3500, episode_reward=-78.40 +/- 13.29\n",
      "Episode length: 32.80 +/- 4.40\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=4000, episode_reward=-73.60 +/- 15.19\n",
      "Episode length: 20.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=4500, episode_reward=-54.80 +/- 0.40\n",
      "Episode length: 20.20 +/- 0.40\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=5000, episode_reward=-67.20 +/- 20.00\n",
      "Episode length: 27.40 +/- 5.82\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=5500, episode_reward=-55.60 +/- 2.73\n",
      "Episode length: 20.80 +/- 0.40\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=6000, episode_reward=-56.80 +/- 3.43\n",
      "Episode length: 28.20 +/- 5.88\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=6500, episode_reward=-54.40 +/- 0.49\n",
      "Episode length: 20.60 +/- 0.49\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=7000, episode_reward=-44.40 +/- 4.80\n",
      "Episode length: 29.20 +/- 0.40\n",
      "New best mean reward!\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=7500, episode_reward=-54.00 +/- 0.00\n",
      "Episode length: 31.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=8000, episode_reward=-51.00 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=8500, episode_reward=-51.00 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=9000, episode_reward=-51.00 +/- 0.00\n",
      "Episode length: 31.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=9500, episode_reward=-48.60 +/- 1.20\n",
      "Episode length: 29.20 +/- 0.40\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Eval num_timesteps=10000, episode_reward=-48.00 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n",
      "Sending message: reset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-28 20:03:57,849] Trial 4 finished with value: -48.0 and parameters: {'learning_rate': 3.2243775007763094e-05, 'buffer_size': 23335, 'batch_size': 32, 'gamma': 0.9425402178303517, 'exploration_fraction': 0.27687288025671425, 'exploration_final_eps': 0.012090955143464824}. Best is trial 4 with value: -48.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WebSocket connection closed.\n",
      "Best hyperparameters:  {'learning_rate': 3.2243775007763094e-05, 'buffer_size': 23335, 'batch_size': 32, 'gamma': 0.9425402178303517, 'exploration_fraction': 0.27687288025671425, 'exploration_final_eps': 0.012090955143464824}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import asyncio\n",
    "import websockets\n",
    "from pydantic import BaseModel\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import json\n",
    "from ClassPVPOKE import PVPokeEnv\n",
    "\n",
    "# Define the objective function\n",
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-3)\n",
    "    buffer_size = trial.suggest_int('buffer_size', 10000, 100000)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128, 256])\n",
    "    gamma = trial.suggest_uniform('gamma', 0.9, 0.999)\n",
    "    exploration_fraction = trial.suggest_uniform('exploration_fraction', 0.1, 0.5)\n",
    "    exploration_final_eps = trial.suggest_uniform('exploration_final_eps', 0.01, 0.1)\n",
    "    \n",
    "    # Create and connect environment\n",
    "    env = PVPokeEnv(\"ws://localhost:8000/ws\", \"notebook\", \"pvpoke\")\n",
    "    env.loop.run_until_complete(env.connect())\n",
    "    \n",
    "    # Create the DQN model\n",
    "    model = DQN(\n",
    "        \"MlpPolicy\",\n",
    "        env,\n",
    "        learning_rate=learning_rate,\n",
    "        buffer_size=buffer_size,\n",
    "        learning_starts=500,\n",
    "        batch_size=batch_size,\n",
    "        gamma=gamma,\n",
    "        train_freq=4,\n",
    "        gradient_steps=1,\n",
    "        target_update_interval=500,\n",
    "        exploration_fraction=exploration_fraction,\n",
    "        exploration_initial_eps=1.0,\n",
    "        exploration_final_eps=exploration_final_eps,\n",
    "        tensorboard_log=\"./dqn_pvpoke_tensorboard/\"\n",
    "    )\n",
    "    \n",
    "    # Create evaluation callback\n",
    "    eval_callback = EvalCallback(env, best_model_save_path='./logs/',\n",
    "                                 log_path='./logs/', eval_freq=500,\n",
    "                                 deterministic=True, render=False)\n",
    "    \n",
    "    # Train the model\n",
    "    model.learn(total_timesteps=10000, callback=eval_callback)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "    \n",
    "    # Close the environment\n",
    "    env.close()\n",
    "    \n",
    "    return mean_reward\n",
    "\n",
    "# Create the study and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters: \", study.best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
